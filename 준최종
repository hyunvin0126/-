# -*- coding: utf-8 -*-
"""
ì¤‘êµ­ì¸ ìœ í•™ìƒ ì›”ì²œì´ì˜ í•œêµ­ ì·¨ì—… ë„ìš°ë¯¸
- í•œêµ­ì–´/ì¤‘êµ­ì–´ ëª¨ë“œ ì§€ì›
- ì§ë¬´ ì¶”ì²œ, ì§€ì› í˜„í™©, ì±„ìš©ê³µê³  í¬ë¡¤ë§, ëª…ì–¸
- ê³µê³µê¸°ê´€ ì–´í•™ ê¸°ì¤€ í¬ë¡¤ë§ (TOEIC ê³µì‹ ì‚¬ì´íŠ¸)
"""

from __future__ import annotations
from dataclasses import dataclass, field
from typing import List, Dict, Any
import random
import requests
from bs4 import BeautifulSoup
import csv
import time
import re
from datetime import datetime

# ==========================
# ì „ì—­ ì–¸ì–´ ì„¤ì • ë° í…ìŠ¤íŠ¸
# ==========================

LANG = "ko"  # ko ë˜ëŠ” zh

TEXT: Dict[str, Dict[str, str]] = {
    "ko": {
        "app_title": "ì¤‘êµ­ì¸ ìœ í•™ìƒ ì›”ì²œì´ì˜ í•œêµ­ ì·¨ì—… ë„ìš°ë¯¸",
        "menu_1": "1. ì›”ì²œì´ í”„ë¡œí•„ & ì–´í•™ ì ìˆ˜ ì…ë ¥",
        "menu_2": "2. ì§ë¬´ ì¶”ì²œ + ì§ë¬´ë³„ ì—­ëŸ‰ ë¶„ì„",
        "menu_3": "3. ì§€ì› í˜„í™© & ê³µê¸°ì—… í† ìµ ì»· ì²´í¬",
        "menu_4": "4. ìµœì‹  ì±„ìš©ê³µê³  ë³´ê¸° (ì‹¤ì‹œê°„ í¬ë¡¤ë§, ì¤‘êµ­ì¸ ìœ í•™ìƒ í•„í„°)",
        "menu_5": "5. ì»¤ë¦¬ì–´/ì„±ê³µ ëª…ì–¸ ëœë¤ ë³´ê¸°",
        "menu_6": "6. ì–¸ì–´ ì„¤ì • (í•œêµ­ì–´/ì¤‘êµ­ì–´)",
        "menu_0": "0. ì¢…ë£Œ",
        "prompt_choice": "ë©”ë‰´ë¥¼ ì„ íƒí•˜ì„¸ìš”: ",
        "invalid_choice": "0~6 ì‚¬ì´ì˜ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.",
        "exit_msg": "í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤!",

        # ì–¸ì–´ ì„¤ì •
        "lang_menu_title": "[ì–¸ì–´ ì„¤ì •]",
        "lang_current": "í˜„ì¬ ì–¸ì–´: ",
        "lang_ko": "í•œêµ­ì–´",
        "lang_zh": "ì¤‘êµ­ì–´",
        "lang_select": "ë³€ê²½í•  ì–¸ì–´ë¥¼ ì„ íƒí•˜ì„¸ìš” (1: í•œêµ­ì–´, 2: ì¤‘êµ­ì–´, 0: ëŒì•„ê°€ê¸°): ",
        "lang_changed_ko": "ì–¸ì–´ê°€ 'í•œêµ­ì–´'ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.",
        "lang_changed_zh": "ì–¸ì–´ê°€ 'ì¤‘êµ­ì–´'ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.",

        # ê¸°ëŠ¥ íƒ€ì´í‹€
        "profile_title": "[ì›”ì²œì´ í”„ë¡œí•„ & ì–´í•™ ì ìˆ˜ ì…ë ¥]",
        "jobs_title": "[ì§ë¬´ ì¶”ì²œ + ì§ë¬´ë³„ ì—­ëŸ‰ ë¶„ì„]",
        "apply_title": "[ì§€ì› í˜„í™© & ê³µê¸°ì—… í† ìµ ì»· ì²´í¬]",
        "crawl_title": "[ìµœì‹  ì±„ìš©ê³µê³  ë³´ê¸° (ì‹¤ì‹œê°„ í¬ë¡¤ë§, ì¤‘êµ­ì¸ ìœ í•™ìƒ í•„í„°)]",
        "quote_title": "[ì»¤ë¦¬ì–´/ì„±ê³µ ëª…ì–¸]",

        "press_enter": "ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...",

        # í”„ë¡œí•„ ê´€ë ¨
        "ask_name": "ì´ë¦„(ë‹‰ë„¤ì„) ì…ë ¥: ",
        "ask_major_strength": "ì „ê³µ ê°•ì (ì˜ˆ: ìƒì‚°, í’ˆì§ˆ, ë°ì´í„° ë“±, ì‰¼í‘œë¡œ êµ¬ë¶„): ",
        "ask_toeic": "TOEIC ì ìˆ˜ ì…ë ¥ (ì—†ìœ¼ë©´ 0): ",
        "ask_topik": "TOPIK(í•œêµ­ì–´ëŠ¥ë ¥ì‹œí—˜) ê¸‰ìˆ˜ ì…ë ¥ (ì˜ˆ: 3, 4, 5, 6 / ì—†ìœ¼ë©´ 0): ",
        "ask_korean_level": "í•œêµ­ì–´ íšŒí™” ìì‹ ê° (1~5): ",
        "ask_chinese_level": "ì¤‘êµ­ì–´ ìì‹ ê° (1~5, ëª¨êµ­ì–´ë©´ 5): ",
        "ask_coding_level": "ì½”ë”©/ë°ì´í„°(íŒŒì´ì¬) ìì‹ ê° (1~5): ",
        "ask_prefer_fields": "ê´€ì‹¬ ì§ë¬´ ë¶„ì•¼ (ì˜ˆ: ìƒì‚°, ë¬¼ë¥˜, ë°ì´í„°, ë§ˆì¼€íŒ…/í•´ì™¸ì˜ì—… / ì‰¼í‘œë¡œ êµ¬ë¶„): ",
        "profile_saved": "í”„ë¡œí•„ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.",

        # ì§ë¬´ ì¶”ì²œ ê´€ë ¨
        "jobs_no_profile": "ë¨¼ì € 1ë²ˆ ë©”ë‰´ì—ì„œ í”„ë¡œí•„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.",
        "jobs_recommend_title": "\n[ì¶”ì²œ ì§ë¬´ ëª©ë¡]",
        "jobs_select_prompt": "ìì„¸íˆ ë³´ê³  ì‹¶ì€ ì§ë¬´ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš” (0: ëŒì•„ê°€ê¸°): ",
        "jobs_detail_title": "\n[ì„ íƒí•œ ì§ë¬´ì˜ ì—­ëŸ‰ ë¶„ì„]",

        # ì—­ëŸ‰ ì´ë¦„
        "skill_korean": "í•œêµ­ì–´",
        "skill_chinese": "ì¤‘êµ­ì–´",
        "skill_english": "ì˜ì–´(TOEIC)",
        "skill_major": "ì „ê³µ/ì‚°ê³µ",
        "skill_coding": "ì½”ë”©/ë°ì´í„°",

        "level_strong": "ê°•ì ",
        "level_normal": "ë³´í†µ",
        "level_weak": "ë³´ì™„ í•„ìš”",

        # ì§€ì› í˜„í™© / ê³µê¸°ì—…
        "apply_menu_title": "[ì§€ì› í˜„í™© & ê³µê¸°ì—… í† ìµ ì»· ì²´í¬]",
        "apply_menu_1": "1) ì§€ì› ë‚´ì—­ ì¶”ê°€",
        "apply_menu_2": "2) ì§€ì› ë‚´ì—­ ë³´ê¸°",
        "apply_menu_3": "3) ê³µê¸°ì—… í† ìµ ì»· ì²´í¬",
        "apply_menu_4": "4) ê³µê³µê¸°ê´€ ì–´í•™ ê¸°ì¤€ í¬ë¡¤ë§ (TOEIC ì‚¬ì´íŠ¸)",
        "apply_menu_0": "0) ëŒì•„ê°€ê¸°",

        "ask_company": "íšŒì‚¬ ì´ë¦„: ",
        "ask_job_title": "ì§€ì› ì§ë¬´ëª…: ",
        "ask_company_type": "íšŒì‚¬ ìœ í˜• (ê³µê¸°ì—…/ëŒ€ê¸°ì—…/ì¤‘ì†Œ/ì™¸êµ­ê³„ ë“±): ",
        "ask_status": "í˜„ì¬ ì§€ì› ìƒíƒœ (ì§€ì›ì™„ë£Œ/ì„œë¥˜í•©ê²©/ë©´ì ‘/ë¶ˆí•©ê²© ë“±): ",
        "ask_is_public": "ê³µê¸°ì—…ì¸ê°€ìš”? (y/n): ",
        "ask_toeic_cut": "í•´ë‹¹ íšŒì‚¬(ê³µê¸°ì—…)ì˜ í† ìµ ì»· ì ìˆ˜ (ì˜ˆ: 700, ëª¨ë¥´ë©´ 0): ",
        "ask_foreigner_friendly": "ì™¸êµ­ì¸/ìœ í•™ìƒ ì§€ì› ê°€ëŠ¥ ê¸°ì—…ì¸ê°€ìš”? (y/n): ",
        "apply_added": "ì§€ì› ë‚´ì—­ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.",

        "apply_list_title": "\n[ì§€ì› ë‚´ì—­]",
        "apply_empty": "í˜„ì¬ ë“±ë¡ëœ ì§€ì› ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤.",

        "toeic_needed": "ë¨¼ì € í”„ë¡œí•„ì˜ TOEIC ì ìˆ˜ë¥¼ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.",
        "check_public_result_title": "\n[ê³µê¸°ì—… í† ìµ ì»· ì²´í¬ ê²°ê³¼]",

        # í¬ë¡¤ë§ ì•ˆë‚´
        "crawl_list_title": "\n[ì¤‘êµ­ì¸ ìœ í•™ìƒì—ê²Œ ìœ ë¦¬í•œ ì±„ìš©ê³µê³ ]",
        "crawl_no_match": "ì¡°ê±´ì— ë§ëŠ” ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤.",
    },
    "zh": {
        "app_title": "ä¸­å›½ç•™å­¦ç”Ÿæœˆå·çš„éŸ©å›½æ±‚èŒåŠ©æ‰‹",
        "menu_1": "1. æœˆå·ä¸ªäººèµ„æ–™ & è¯­è¨€æˆç»©è¾“å…¥",
        "menu_2": "2. èŒä½æ¨è + èŒä½èƒ½åŠ›åˆ†æ",
        "menu_3": "3. æŠ•é€’è®°å½• & å…¬ä¼ä¸š TOEIC æ ¸å¯¹",
        "menu_4": "4. æœ€æ–°æ‹›è˜ä¿¡æ¯æŸ¥çœ‹ï¼ˆå®æ—¶çˆ¬å–ï¼Œé€‚åˆä¸­å›½ç•™å­¦ç”Ÿï¼‰",
        "menu_5": "5. èŒä¸š/æˆåŠŸåè¨€ éšæœºæŸ¥çœ‹",
        "menu_6": "6. è¯­è¨€è®¾ç½®ï¼ˆéŸ©æ–‡/ä¸­æ–‡ï¼‰",
        "menu_0": "0. é€€å‡º",
        "prompt_choice": "è¯·é€‰æ‹©èœå•: ",
        "invalid_choice": "è¯·è¾“å…¥ 0~6 ä¹‹é—´çš„æ•°å­—ã€‚",
        "exit_msg": "ç¨‹åºç»“æŸï¼Œè¾›è‹¦äº†ï¼",

        # ì–¸ì–´ ì„¤ì •
        "lang_menu_title": "[è¯­è¨€è®¾ç½®]",
        "lang_current": "å½“å‰è¯­è¨€: ",
        "lang_ko": "éŸ©æ–‡",
        "lang_zh": "ä¸­æ–‡",
        "lang_select": "è¯·é€‰æ‹©è¯­è¨€ (1: éŸ©æ–‡, 2: ä¸­æ–‡, 0: è¿”å›): ",
        "lang_changed_ko": 'è¯­è¨€å·²åˆ‡æ¢ä¸º"éŸ©æ–‡"ã€‚',
        "lang_changed_zh": 'è¯­è¨€å·²åˆ‡æ¢ä¸º"ä¸­æ–‡"ã€‚',

        # ê¸°ëŠ¥ íƒ€ì´í‹€
        "profile_title": "[æœˆå·ä¸ªäººèµ„æ–™ & è¯­è¨€æˆç»©è¾“å…¥]",
        "jobs_title": "[èŒä½æ¨è + èŒä½èƒ½åŠ›åˆ†æ]",
        "apply_title": "[æŠ•é€’è®°å½• & å…¬ä¼ä¸š TOEIC æ ¸å¯¹]",
        "crawl_title": "[æœ€æ–°æ‹›è˜ä¿¡æ¯æŸ¥çœ‹ï¼ˆå®æ—¶çˆ¬å–ï¼Œé€‚åˆä¸­å›½ç•™å­¦ç”Ÿï¼‰]",
        "quote_title": "[èŒä¸š/æˆåŠŸåè¨€]",

        "press_enter": "æŒ‰ Enter ç»§ç»­...",

        # í”„ë¡œí•„ ê´€ë ¨
        "ask_name": "è¯·è¾“å…¥å§“å/æ˜µç§°: ",
        "ask_major_strength": "ä¸“ä¸šä¼˜åŠ¿ï¼ˆä¾‹å¦‚ï¼šç”Ÿäº§ï¼Œè´¨é‡ï¼Œæ•°æ®ç­‰ï¼Œç”¨é€—å·åˆ†éš”ï¼‰: ",
        "ask_toeic": "è¯·è¾“å…¥ TOEIC åˆ†æ•°ï¼ˆæ²¡æœ‰åˆ™è¾“å…¥ 0ï¼‰: ",
        "ask_topik": "è¯·è¾“å…¥ TOPIK ç­‰çº§ï¼ˆä¾‹å¦‚ï¼š3,4,5,6ï¼Œæ²¡æœ‰åˆ™ 0ï¼‰: ",
        "ask_korean_level": "éŸ©è¯­å£è¯­è‡ªä¿¡åº¦ (1~5): ",
        "ask_chinese_level": "ä¸­æ–‡è‡ªä¿¡åº¦ (1~5ï¼Œæœ¬å›½è¯­è¨€ä¸€èˆ¬ä¸º 5): ",
        "ask_coding_level": "ç¼–ç¨‹/æ•°æ®(Python) è‡ªä¿¡åº¦ (1~5): ",
        "ask_prefer_fields": "æ„Ÿå…´è¶£çš„èŒä½é¢†åŸŸï¼ˆä¾‹å¦‚ï¼šç”Ÿäº§, ç‰©æµ, æ•°æ®, è¥é”€/æµ·å¤–é”€å”® / ç”¨é€—å·åˆ†éš”ï¼‰: ",
        "profile_saved": "ä¸ªäººèµ„æ–™å·²ä¿å­˜ã€‚",

        # ì§ë¬´ ì¶”ì²œ ê´€ë ¨
        "jobs_no_profile": "è¯·å…ˆåœ¨èœå• 1 ä¸­è¾“å…¥ä¸ªäººèµ„æ–™ã€‚",
        "jobs_recommend_title": "\n[æ¨èèŒä½åˆ—è¡¨]",
        "jobs_select_prompt": "è¯·é€‰æ‹©æƒ³è¯¦ç»†æŸ¥çœ‹çš„èŒä½ç¼–å· (0: è¿”å›): ",
        "jobs_detail_title": "\n[æ‰€é€‰èŒä½çš„èƒ½åŠ›åˆ†æ]",

        "skill_korean": "éŸ©è¯­",
        "skill_chinese": "ä¸­æ–‡",
        "skill_english": "è‹±è¯­(TOEIC)",
        "skill_major": "ä¸“ä¸š/å·¥ç®¡",
        "skill_coding": "ç¼–ç¨‹/æ•°æ®",

        "level_strong": "ä¼˜åŠ¿",
        "level_normal": "ä¸€èˆ¬",
        "level_weak": "éœ€è¦åŠ å¼º",

        # ì§€ì› í˜„í™© / ê³µê¸°ì—…
        "apply_menu_title": "[æŠ•é€’è®°å½• & å…¬ä¼ä¸š TOEIC æ ¸å¯¹]",
        "apply_menu_1": "1) æ–°å¢æŠ•é€’è®°å½•",
        "apply_menu_2": "2) æŸ¥çœ‹æŠ•é€’è®°å½•",
        "apply_menu_3": "3) å…¬ä¼ä¸š TOEIC åˆ†æ•°çº¿æ£€æŸ¥",
        "apply_menu_4": "4) å…¬å…±æœºæ„è¯­è¨€è¦æ±‚çˆ¬å–(TOEIC ç½‘ç«™)",
        "apply_menu_0": "0) è¿”å›",

        "ask_company": "å…¬å¸åç§°: ",
        "ask_job_title": "åº”è˜èŒä½: ",
        "ask_company_type": "å…¬å¸ç±»å‹ï¼ˆå…¬ä¼ä¸š/å¤§ä¼ä¸š/ä¸­å°/å¤–ä¼ ç­‰ï¼‰: ",
        "ask_status": "å½“å‰æŠ•é€’çŠ¶æ€ï¼ˆå·²æŠ•/ä¹¦é¢é€šè¿‡/é¢è¯•ä¸­/æœªé€šè¿‡ ç­‰ï¼‰: ",
        "ask_is_public": "æ˜¯å¦ä¸ºå…¬ä¼ä¸š? (y/n): ",
        "ask_toeic_cut": "è¯¥å…¬ä¼ä¸šçš„ TOEIC åˆ†æ•°çº¿ï¼ˆä¾‹å¦‚ï¼š700ï¼Œä¸æ¸…æ¥šåˆ™ 0ï¼‰: ",
        "ask_foreigner_friendly": "æ˜¯å¦æ¥å—å¤–å›½äºº/ç•™å­¦ç”Ÿ? (y/n): ",
        "apply_added": "æŠ•é€’è®°å½•å·²æ·»åŠ ã€‚",

        "apply_list_title": "\n[æŠ•é€’è®°å½•]",
        "apply_empty": "å½“å‰æ²¡æœ‰ä»»ä½•æŠ•é€’è®°å½•ã€‚",

        "toeic_needed": "è¯·å…ˆåœ¨ä¸ªäººèµ„æ–™ä¸­è¾“å…¥ TOEIC åˆ†æ•°ã€‚",
        "check_public_result_title": "\n[å…¬ä¼ä¸š TOEIC åˆ†æ•°çº¿æ£€æŸ¥ç»“æœ]",

        "crawl_list_title": "\n[é€‚åˆä¸­å›½ç•™å­¦ç”Ÿçš„æ‹›è˜ä¿¡æ¯]",
        "crawl_no_match": "æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„æ‹›è˜ä¿¡æ¯ã€‚",
    }
}


def t(key: str) -> str:
    """í˜„ì¬ ì–¸ì–´(LANG)ì— ë§ëŠ” í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°."""
    return TEXT[LANG].get(key, f"[{key}]")


# ==========================
# ë°ì´í„° ëª¨ë¸ (í´ë˜ìŠ¤)
# ==========================

@dataclass
class JobSeeker:
    name: str = "ì›”ì²œì´"
    major_strengths: List[str] = field(default_factory=list)
    toeic: int = 0
    topik: int = 0
    korean_level: int = 3  # 1~5
    chinese_level: int = 5  # 1~5
    coding_level: int = 3  # 1~5
    prefer_fields: List[str] = field(default_factory=list)

    def english_score_level(self) -> int:
        """TOEIC ì ìˆ˜ë¥¼ 1~5 ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜ (ë‹¨ìˆœí™”)."""
        if self.toeic <= 0:
            return 1
        if self.toeic < 600:
            return 2
        if self.toeic < 750:
            return 3
        if self.toeic < 900:
            return 4
        return 5

    def major_level(self) -> int:
        """ì „ê³µ(ì‚°ì—…ê²½ì˜/ê³µí•™) ìì‹ ê°ì„ 1~5ë¡œ ì¶”ì • (ë‹¨ìˆœ)."""
        return 3 + min(len(self.major_strengths), 2)  # ìµœëŒ€ 5


@dataclass
class JobPosting:
    title: str
    company: str
    location: str
    tags: List[str]
    foreigner_friendly: bool = False


@dataclass
class Application:
    company: str
    job_title: str
    company_type: str
    status: str
    is_public: bool
    toeic_cut: int
    foreigner_friendly: bool


# ==========================
# ê³µê³µê¸°ê´€ ì–´í•™ ê¸°ì¤€ í¬ë¡¤ëŸ¬ (TOEIC ì‚¬ì´íŠ¸)
# ==========================

class PublicInstitutionRecruitCrawler:
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
                          'AppleWebKit/537.36 (KHTML, like Gecko) '
                          'Chrome/91.0.4472.124 Safari/537.36'
        }
        self.results = []

    def crawl_toeic_recruit_page(self):
        """í† ìµ ê³µì‹ ì‚¬ì´íŠ¸ì˜ ì±„ìš©ì •ë³´ í¬ë¡¤ë§"""
        url = "https://exam.toeic.co.kr/recruit/recruit.php"

        try:
            response = requests.get(url, headers=self.headers, timeout=10)
            response.raise_for_status()
            response.encoding = 'utf-8'

            soup = BeautifulSoup(response.text, 'html.parser')

            job_listings = soup.find_all('div', class_='recruit_list')
            if not job_listings:
                job_listings = soup.find_all('li', class_='list')

            for job in job_listings:
                try:
                    company_elem = (
                        job.find('strong')
                        or job.find('h3')
                        or job.find('div', class_='company')
                    )
                    company = company_elem.get_text(strip=True) if company_elem else "N/A"

                    text = job.get_text()

                    recruit_type = self.extract_recruit_type(text, job)
                    period_elem = job.find('span', class_='period') or job.find(
                        'p', class_='date'
                    )
                    period = (
                        period_elem.get_text(strip=True)
                        if period_elem
                        else self.extract_period_from_text(text)
                    )
                    language_req = self.extract_language_requirements(text)
                    department = self.extract_department(text, job)
                    method = self.extract_recruit_method(text, job)

                    self.results.append(
                        {
                            'ê¸°ê´€ëª…': company,
                            'ëª¨ì§‘êµ¬ë¶„': recruit_type,
                            'ì±„ìš©ê¸°ê°„': period,
                            'ì–´í•™ìê²©': language_req,
                            'ì±„ìš©ë¶€ë¬¸': department,
                            'ëª¨ì§‘ë°©ë²•': method,
                            'ì¶œì²˜': 'TOEIC ê³µì‹ ì‚¬ì´íŠ¸',
                        }
                    )

                except Exception as e:
                    print(f"ê°œë³„ ê³µê³  íŒŒì‹± ì˜¤ë¥˜: {e}")
                    continue

            print(f"í† ìµ ê³µì‹ ì‚¬ì´íŠ¸ì—ì„œ {len(job_listings)}ê°œ ê³µê³  ìˆ˜ì§‘ ì™„ë£Œ")

        except Exception as e:
            print(f"í† ìµ ê³µì‹ ì‚¬ì´íŠ¸ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")

    def extract_recruit_type(self, text, job_elem):
        """ëª¨ì§‘êµ¬ë¶„ ì¶”ì¶œ (ì‹ ì…/ê²½ë ¥/ì¸í„´/ê³„ì•½ì§ ë“±)"""
        type_elem = job_elem.find('span', class_='type') or job_elem.find(
            'span', class_='badge'
        )
        if type_elem:
            return type_elem.get_text(strip=True)

        patterns = ['ì‹ ì…', 'ê²½ë ¥', 'ì¸í„´', 'ê³„ì•½ì§', 'ë¬´ê¸°ê³„ì•½ì§', 'ì •ê·œì§', 'íŒŒê²¬ì§']
        for pattern in patterns:
            if pattern in text:
                return pattern

        return "N/A"

    def extract_period_from_text(self, text):
        """í…ìŠ¤íŠ¸ì—ì„œ ì±„ìš©ê¸°ê°„ ì¶”ì¶œ"""
        pattern = r'\d{4}\.\d{1,2}\.\d{1,2}\s*~\s*\d{4}\.\d{1,2}\.\d{1,2}'
        match = re.search(pattern, text)
        if match:
            return match.group(0)

        period_keywords = ['ìƒë°˜ê¸°', 'í•˜ë°˜ê¸°', 'ì—°ì¤‘', 'ìˆ˜ì‹œ']
        for keyword in period_keywords:
            if keyword in text:
                return keyword

        return "N/A"

    def extract_language_requirements(self, text):
        """ì–´í•™ìê²© ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ"""
        requirements = []

        toeic_patterns = [
            r'TOEIC\s*(\d{3,4})\s*ì ?\s*(ì´ìƒ|í•„ìˆ˜|ìš°ëŒ€)?',
            r'í† ìµ\s*(\d{3,4})\s*ì ?\s*(ì´ìƒ|í•„ìˆ˜|ìš°ëŒ€)?',
        ]

        for pattern in toeic_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                score = match.group(1)
                condition = match.group(2) if match.group(2) else ""
                requirements.append(f"TOEIC {score}ì  {condition}".strip())
                break

        speaking_patterns = [
            r'TOEIC\s*Speaking\s*([A-Z]{1,3}\d*|[IA][LMH]\d?|\d{3})\s*(ì´ìƒ|í•„ìˆ˜|ìš°ëŒ€)?',
            r'í† ìµ\s*ìŠ¤í”¼í‚¹\s*([A-Z]{1,3}\d*|[IA][LMH]\d?|\d{3})\s*(ì´ìƒ|í•„ìˆ˜|ìš°ëŒ€)?',
        ]

        for pattern in speaking_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                score = match.group(1)
                condition = match.group(2) if match.group(2) else ""
                requirements.append(f"TOEIC Speaking {score} {condition}".strip())
                break

        if 'TEPS' in text:
            teps_match = re.search(
                r'TEPS\s*(\d{3})\s*(ì´ìƒ|í•„ìˆ˜|ìš°ëŒ€)?', text
            )
            if teps_match:
                requirements.append(
                    f"TEPS {teps_match.group(1)} {teps_match.group(2) or ''}".strip()
                )

        if 'IELTS' in text:
            ielts_match = re.search(
                r'IELTS\s*(\d\.?\d?)\s*(ì´ìƒ|í•„ìˆ˜|ìš°ëŒ€)?', text
            )
            if ielts_match:
                requirements.append(
                    f"IELTS {ielts_match.group(1)} {ielts_match.group(2) or ''}".strip()
                )

        return ' / '.join(requirements) if requirements else "N/A"

    def extract_department(self, text, job_elem):
        """ì±„ìš©ë¶€ë¬¸ ì¶”ì¶œ"""
        dept_elem = job_elem.find('span', class_='dept') or job_elem.find(
            'div', class_='department'
        )
        if dept_elem:
            return dept_elem.get_text(strip=True)

        dept_keywords = [
            'ì‚¬ë¬´ì§',
            'ê¸°ìˆ ì§',
            'ì—°êµ¬ì§',
            'ì˜ì—…ì§',
            'ê´€ë¦¬ì§',
            'ì‚¬ë¬´',
            'ê¸°ìˆ ',
            'ì—°êµ¬',
            'ì˜ì—…',
            'ê´€ë¦¬',
            'IT',
            'ê°œë°œ',
            'ì¸ì‚¬',
            'íšŒê³„',
            'ë§ˆì¼€íŒ…',
        ]
        for keyword in dept_keywords:
            if keyword in text:
                return keyword

        return "N/A"

    def extract_recruit_method(self, text, job_elem):
        """ëª¨ì§‘ë°©ë²• ì¶”ì¶œ"""
        method_elem = job_elem.find('span', class_='method') or job_elem.find(
            'div', class_='apply_method'
        )
        if method_elem:
            return method_elem.get_text(strip=True)

        if 'ì„œë¥˜ì „í˜•' in text and 'ë©´ì ‘' in text:
            return "ì„œë¥˜ì „í˜• + ë©´ì ‘"
        elif 'ì„œë¥˜ì „í˜•' in text:
            return "ì„œë¥˜ì „í˜•"
        elif 'ê³µê°œì±„ìš©' in text:
            return "ê³µê°œì±„ìš©"
        elif 'ìˆ˜ì‹œì±„ìš©' in text:
            return "ìˆ˜ì‹œì±„ìš©"
        elif 'íŠ¹ë³„ì±„ìš©' in text:
            return "íŠ¹ë³„ì±„ìš©"

        return "N/A"

    def add_known_public_institutions(self):
        """ì•Œë ¤ì§„ ê³µê³µê¸°ê´€ ì–´í•™ ê¸°ì¤€ ë°ì´í„° ì¶”ê°€"""
        known_data = [
            {
                'ê¸°ê´€ëª…': 'í•œêµ­ì „ë ¥ê³µì‚¬',
                'ëª¨ì§‘êµ¬ë¶„': 'ì‹ ì…',
                'ì±„ìš©ê¸°ê°„': 'ìƒë°˜ê¸°/í•˜ë°˜ê¸°',
                'ì–´í•™ìê²©': 'TOEIC 700ì  í•„ìˆ˜ (ì„œë¥˜ ë§Œì : ì‚¬ë¬´ì§ 850ì , ê¸°ìˆ ì§ 800ì )',
                'ì±„ìš©ë¶€ë¬¸': 'ì‚¬ë¬´ì§/ê¸°ìˆ ì§',
                'ëª¨ì§‘ë°©ë²•': 'ê³µê°œì±„ìš© (ì„œë¥˜ì „í˜• + ë©´ì ‘)',
                'ì¶œì²˜': '2024-2025 ì±„ìš© ê³µê³ ',
            },
            {
                'ê¸°ê´€ëª…': 'í•œêµ­ìˆ˜ë ¥ì›ìë ¥',
                'ëª¨ì§‘êµ¬ë¶„': 'ì‹ ì…',
                'ì±„ìš©ê¸°ê°„': 'ì—°ì¤‘',
                'ì–´í•™ìê²©': 'TOEIC 700ì  í•„ìˆ˜ (ì„œë¥˜ ë§Œì : 850ì )',
                'ì±„ìš©ë¶€ë¬¸': 'ê¸°ìˆ ì§',
                'ëª¨ì§‘ë°©ë²•': 'ê³µê°œì±„ìš©',
                'ì¶œì²˜': '2024 ì±„ìš© ê³µê³ ',
            },
            {
                'ê¸°ê´€ëª…': 'í•œêµ­ì„œë¶€ë°œì „',
                'ëª¨ì§‘êµ¬ë¶„': 'ì‹ ì…',
                'ì±„ìš©ê¸°ê°„': 'ì—°ì¤‘',
                'ì–´í•™ìê²©': 'TOEIC ë§Œì  ê¸°ì¤€ 900ì ',
                'ì±„ìš©ë¶€ë¬¸': 'ê¸°ìˆ ì§',
                'ëª¨ì§‘ë°©ë²•': 'ê³µê°œì±„ìš©',
                'ì¶œì²˜': '2024 ì±„ìš© ê³µê³ ',
            },
            {
                'ê¸°ê´€ëª…': 'êµ­ë¯¼ì—°ê¸ˆê³µë‹¨',
                'ëª¨ì§‘êµ¬ë¶„': 'ì‹ ì…',
                'ì±„ìš©ê¸°ê°„': 'ì—°ì¤‘',
                'ì–´í•™ìê²©': 'TOEIC 700ì  í•„ìˆ˜ (700ì  ì´ìƒ ë™ì )',
                'ì±„ìš©ë¶€ë¬¸': 'ì‚¬ë¬´ì§',
                'ëª¨ì§‘ë°©ë²•': 'ê³µê°œì±„ìš©',
                'ì¶œì²˜': '2024 ì±„ìš© ê³µê³ ',
            },
            {
                'ê¸°ê´€ëª…': 'êµ­ë¯¼ê±´ê°•ë³´í—˜ê³µë‹¨',
                'ëª¨ì§‘êµ¬ë¶„': 'ì‹ ì…',
                'ì±„ìš©ê¸°ê°„': 'ì—°ì¤‘',
                'ì–´í•™ìê²©': 'TOEIC 700ì  í•„ìˆ˜ (700ì  ì´ìƒ ë™ì )',
                'ì±„ìš©ë¶€ë¬¸': 'ì‚¬ë¬´ì§',
                'ëª¨ì§‘ë°©ë²•': 'ê³µê°œì±„ìš©',
                'ì¶œì²˜': '2024 ì±„ìš© ê³µê³ ',
            },
            {
                'ê¸°ê´€ëª…': 'í•œêµ­ìˆ˜ìì›ê³µì‚¬',
                'ëª¨ì§‘êµ¬ë¶„': 'ì‹ ì…',
                'ì±„ìš©ê¸°ê°„': 'ì—°ì¤‘',
                'ì–´í•™ìê²©': 'TOEIC 900ì  ì´ìƒ (ê¸°ìˆ ì§ í¬í•¨)',
                'ì±„ìš©ë¶€ë¬¸': 'ì‚¬ë¬´ì§/ê¸°ìˆ ì§',
                'ëª¨ì§‘ë°©ë²•': 'ê³µê°œì±„ìš©',
                'ì¶œì²˜': '2024 ì±„ìš© ê³µê³ ',
            },
        ]
        self.results.extend(known_data)
        print(f"ì•Œë ¤ì§„ ê³µê³µê¸°ê´€ {len(known_data)}ê°œ ë°ì´í„° ì¶”ê°€ ì™„ë£Œ")

    def save_to_csv(self, filename=None):
        """ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"ê³µê³µê¸°ê´€_ì±„ìš©ì •ë³´_{timestamp}.csv"

        if not self.results:
            print("ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        with open(filename, 'w', newline='', encoding='utf-8-sig') as f:
            fieldnames = [
                'ê¸°ê´€ëª…',
                'ëª¨ì§‘êµ¬ë¶„',
                'ì±„ìš©ê¸°ê°„',
                'ì–´í•™ìê²©',
                'ì±„ìš©ë¶€ë¬¸',
                'ëª¨ì§‘ë°©ë²•',
                'ì¶œì²˜',
            ]
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            for row in self.results:
                writer.writerow(row)

        print(f"\nâœ… CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filename}")
        print(f"ì´ {len(self.results)}ê°œì˜ ë°ì´í„° ìˆ˜ì§‘")

    def run(self):
        """í¬ë¡¤ëŸ¬ ì‹¤í–‰"""
        print("=" * 60)
        print("ê³µê³µê¸°ê´€ ì±„ìš©/ì–´í•™ ê¸°ì¤€ í¬ë¡¤ëŸ¬ ì‹œì‘")
        print("=" * 60)

        print("\n[1/2] í† ìµ ê³µì‹ ì‚¬ì´íŠ¸ í¬ë¡¤ë§ ì¤‘...")
        self.crawl_toeic_recruit_page()
        time.sleep(2)

        print("\n[2/2] ì•Œë ¤ì§„ ê³µê³µê¸°ê´€ ë°ì´í„° ì¶”ê°€ ì¤‘...")
        self.add_known_public_institutions()

        print("\n[ì™„ë£Œ] CSV íŒŒì¼ ì €ì¥ ì¤‘...")
        self.save_to_csv()

        print("\n" + "=" * 60)
        print("ìˆ˜ì§‘ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 5ê°œ)")
        print("=" * 60)
        for i, item in enumerate(self.results[:5], 1):
            print(f"\n{i}. {item['ê¸°ê´€ëª…']}")
            print(f"   - ëª¨ì§‘êµ¬ë¶„: {item['ëª¨ì§‘êµ¬ë¶„']}")
            print(f"   - ì±„ìš©ê¸°ê°„: {item['ì±„ìš©ê¸°ê°„']}")
            print(f"   - ì–´í•™ìê²©: {item['ì–´í•™ìê²©']}")
            print(f"   - ì±„ìš©ë¶€ë¬¸: {item['ì±„ìš©ë¶€ë¬¸']}")
            print(f"   - ëª¨ì§‘ë°©ë²•: {item['ëª¨ì§‘ë°©ë²•']}")


# ==========================
# ì‚¬ëŒì¸ ì±„ìš©ê³µê³  í¬ë¡¤ëŸ¬ (JobPosting ìš©)
# ==========================

class SaraminJobCrawler:
    """ì‚¬ëŒì¸ì—ì„œ ì±„ìš©ê³µê³ ë¥¼ ê°€ì ¸ì™€ JobPosting ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¤ì–´ì£¼ëŠ” í´ë˜ìŠ¤"""

    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
                          'AppleWebKit/537.36 (KHTML, like Gecko) '
                          'Chrome/120.0.0.0 Safari/537.36'
        }
        self.jobs: List[JobPosting] = []

    def crawl(self, keyword: str = "ì¤‘êµ­ì–´", pages: int = 1):
        """
        ì‚¬ëŒì¸ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì±„ìš©ê³µê³  í¬ë¡¤ë§
        - keyword: ê²€ìƒ‰ì–´ (ì˜ˆ: 'ì¤‘êµ­ì–´', 'ë¬´ì—­', 'ë°ì´í„°')
        - pages: ëª‡ í˜ì´ì§€ê¹Œì§€ ë³¼ì§€ (1~3 ì •ë„ ì¶”ì²œ)
        """
        base = (
            "https://www.saramin.co.kr/zf_user/search/recruit"
            "?searchType=search"
            f"&searchword={keyword}"
            "&recruitPage={page}"
            "&recruitSort=reg_dt"
            "&recruitPageCount=20"
        )

        for page in range(1, pages + 1):
            url = base.format(page=page)
            try:
                resp = requests.get(url, headers=self.headers, timeout=10)
                resp.raise_for_status()
                soup = BeautifulSoup(resp.text, "html.parser")

                items = soup.select("div.item_recruit")
                if not items:
                    print(f"âš ï¸ {page}í˜ì´ì§€ì—ì„œ ê³µê³ ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                    continue

                for item in items:
                    try:
                        corp_tag = item.select_one("strong.corp_name a")
                        company = corp_tag.get_text(strip=True) if corp_tag else "ì •ë³´ ì—†ìŒ"

                        title_tag = item.select_one("h2.job_tit a")
                        title = title_tag.get_text(strip=True) if title_tag else "ì •ë³´ ì—†ìŒ"

                        cond_spans = item.select("div.job_condition span")
                        cond_texts = [c.get_text(strip=True) for c in cond_spans]
                        location = cond_texts[0] if cond_texts else "ì§€ì—­ ì •ë³´ ì—†ìŒ"
                        tags = cond_texts[1:] if len(cond_texts) > 1 else []

                        full_text = f"{company} {title}".lower()
                        foreigner_friendly = any(
                            kw in full_text
                            for kw in ["ì¤‘êµ­", "ì¤‘êµ­ì–´", "chinese", "ì™¸êµ­ì¸", "ìœ í•™ìƒ"]
                        )

                        self.jobs.append(
                            JobPosting(
                                title=title,
                                company=company,
                                location=location,
                                tags=tags,
                                foreigner_friendly=foreigner_friendly,
                            )
                        )
                    except Exception as e:
                        print(f"âš ï¸ ê°œë³„ ê³µê³  íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue

                print(f"âœ… ì‚¬ëŒì¸ {page}í˜ì´ì§€ í¬ë¡¤ë§ ì™„ë£Œ (ëˆ„ì  {len(self.jobs)}ê°œ)")
                time.sleep(1)

            except Exception as e:
                print(f"âŒ ì‚¬ëŒì¸ {page}í˜ì´ì§€ ìš”ì²­ ì˜¤ë¥˜: {e}")
                continue


# ì „ì—­ ìƒíƒœ
job_seeker = JobSeeker()
applications: List[Application] = []


# ì§ë¬´ ì •ì˜: ë¶„ì•¼ + ê°€ì¤‘ì¹˜
JOB_ROLES: Dict[str, Dict[str, Any]] = {
    "ìƒì‚°ê´€ë¦¬": {
        "field": "ìƒì‚°",
        "weights": {
            "korean": 0.2,
            "chinese": 0.1,
            "english": 0.1,
            "major": 0.4,
            "coding": 0.2,
        },
    },
    "í’ˆì§ˆê´€ë¦¬": {
        "field": "ìƒì‚°",
        "weights": {
            "korean": 0.25,
            "chinese": 0.05,
            "english": 0.1,
            "major": 0.4,
            "coding": 0.2,
        },
    },
    "ë¬¼ë¥˜/SCM ê¸°íš": {
        "field": "ë¬¼ë¥˜",
        "weights": {
            "korean": 0.25,
            "chinese": 0.2,
            "english": 0.2,
            "major": 0.25,
            "coding": 0.1,
        },
    },
    "í•´ì™¸ ë¬¼ë¥˜ ìš´ì˜(ì¤‘êµ­)": {
        "field": "ë¬¼ë¥˜",
        "weights": {
            "korean": 0.25,
            "chinese": 0.3,
            "english": 0.2,
            "major": 0.15,
            "coding": 0.1,
        },
    },
    "ë°ì´í„° ë¶„ì„": {
        "field": "ë°ì´í„°",
        "weights": {
            "korean": 0.15,
            "chinese": 0.05,
            "english": 0.2,
            "major": 0.25,
            "coding": 0.35,
        },
    },
    "BI/ë°ì´í„° ë¦¬í¬íŒ…": {
        "field": "ë°ì´í„°",
        "weights": {
            "korean": 0.25,
            "chinese": 0.05,
            "english": 0.2,
            "major": 0.25,
            "coding": 0.25,
        },
    },
    "í•´ì™¸ì˜ì—…(ì¤‘êµ­ ë‹´ë‹¹)": {
        "field": "ë§ˆì¼€íŒ…/í•´ì™¸ì˜ì—…",
        "weights": {
            "korean": 0.25,
            "chinese": 0.3,
            "english": 0.2,
            "major": 0.15,
            "coding": 0.1,
        },
    },
    "ì¤‘êµ­ ë§ˆì¼€íŒ…": {
        "field": "ë§ˆì¼€íŒ…/í•´ì™¸ì˜ì—…",
        "weights": {
            "korean": 0.3,
            "chinese": 0.3,
            "english": 0.1,
            "major": 0.1,
            "coding": 0.2,
        },
    },
}


# ==========================
# 1. í”„ë¡œí•„ & ì–´í•™ ì ìˆ˜ ì…ë ¥
# ==========================

def handle_profile() -> None:
    global job_seeker
    print("\n" + t("profile_title"))

    name = input(t("ask_name"))
    major_str = input(t("ask_major_strength"))
    toeic_str = input(t("ask_toeic"))
    topik_str = input(t("ask_topik"))
    korean_str = input(t("ask_korean_level"))
    chinese_str = input(t("ask_chinese_level"))
    coding_str = input(t("ask_coding_level"))
    prefer_str = input(t("ask_prefer_fields"))

    def to_int_safe(s: str, default: int = 0) -> int:
        try:
            return int(s)
        except ValueError:
            return default

    toeic = to_int_safe(toeic_str, 0)
    topik = to_int_safe(topik_str, 0)
    korean = min(max(to_int_safe(korean_str, 3), 1), 5)
    chinese = min(max(to_int_safe(chinese_str, 5), 1), 5)
    coding = min(max(to_int_safe(coding_str, 3), 1), 5)

    major_strengths = [s.strip() for s in major_str.split(",") if s.strip()]
    prefer_fields = [s.strip() for s in prefer_str.split(",") if s.strip()]

    job_seeker = JobSeeker(
        name=name or "ì›”ì²œì´",
        major_strengths=major_strengths,
        toeic=toeic,
        topik=topik,
        korean_level=korean,
        chinese_level=chinese,
        coding_level=coding,
        prefer_fields=prefer_fields,
    )

    print("\n" + t("profile_saved") + "\n")
    input(t("press_enter"))


# ==========================
# 2. ì§ë¬´ ì¶”ì²œ + ì—­ëŸ‰ ë¶„ì„
# ==========================

def handle_jobs() -> None:
    if (
        not job_seeker.major_strengths
        and job_seeker.toeic == 0
        and job_seeker.topik == 0
        and not job_seeker.prefer_fields
    ):
        print("\n" + t("jobs_no_profile"))
        input(t("press_enter"))
        return

    print("\n" + t("jobs_title"))

    fields = sorted({meta["field"] for meta in JOB_ROLES.values()})
    print("\n[ì§ë¬´ ë¶„ì•¼ ì„ íƒ]")
    for idx, field_name in enumerate(fields, start=1):
        print(f"{idx}. {field_name}")
    print("0. ëŒì•„ê°€ê¸°\n")

    while True:
        choice = input("ë³´ê³  ì‹¶ì€ ì§ë¬´ ë¶„ì•¼ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš”: ").strip()
        if choice == "0":
            return
        try:
            f_idx = int(choice) - 1
        except ValueError:
            print(t("invalid_choice"))
            continue

        if 0 <= f_idx < len(fields):
            selected_field = fields[f_idx]
            break
        else:
            print(t("invalid_choice"))

    scores = []
    for role_name, meta in JOB_ROLES.items():
        if meta["field"] != selected_field:
            continue
        weights = meta["weights"]
        score = calc_job_match_score(weights, job_seeker)
        scores.append((role_name, score, weights))

    if not scores:
        print("\ní•´ë‹¹ ë¶„ì•¼ì— ë“±ë¡ëœ ì§ë¬´ê°€ ì—†ìŠµë‹ˆë‹¤.\n")
        input(t("press_enter"))
        return

    scores.sort(key=lambda x: x[1], reverse=True)

    print(t("jobs_recommend_title"))
    print(f"ì„ íƒí•œ ë¶„ì•¼: {selected_field}\n")
    for idx, (role, sc, _) in enumerate(scores, start=1):
        print(f"{idx}. {role}  (ë§¤ì¹­ ì ìˆ˜: {sc:.1f})")
    print()

    while True:
        choice = input(t("jobs_select_prompt")).strip()
        if choice == "0":
            break
        try:
            idx = int(choice) - 1
        except ValueError:
            print(t("invalid_choice"))
            continue

        if 0 <= idx < len(scores):
            role_name, _, weights = scores[idx]
            show_job_detail(role_name, weights, job_seeker)
            break
        else:
            print(t("invalid_choice"))

    input(t("press_enter"))


def calc_job_match_score(weights: Dict[str, float], seeker: JobSeeker) -> float:
    """ì§ë¬´ë³„ ê°€ì¤‘ì¹˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ 0~100 ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°."""
    korean = seeker.korean_level
    chinese = seeker.chinese_level
    english = seeker.english_score_level()
    major = seeker.major_level()
    coding = seeker.coding_level

    total = 0.0
    total_weight = 0.0

    total += korean * weights.get("korean", 0)
    total_weight += weights.get("korean", 0)

    total += chinese * weights.get("chinese", 0)
    total_weight += weights.get("chinese", 0)

    total += english * weights.get("english", 0)
    total_weight += weights.get("english", 0)

    total += major * weights.get("major", 0)
    total_weight += weights.get("major", 0)

    total += coding * weights.get("coding", 0)
    total_weight += weights.get("coding", 0)

    if total_weight == 0:
        return 0.0

    avg = total / total_weight  # 1~5 ë²”ìœ„
    return avg / 5.0 * 100.0   # 0~100


def show_job_detail(role_name: str, weights: Dict[str, float], seeker: JobSeeker) -> None:
    """ì„ íƒí•œ ì§ë¬´ì— ëŒ€í•´ ì—­ëŸ‰ë³„ ë¶„ì„ ì¶œë ¥."""
    print("\n" + t("jobs_detail_title"))
    print(f"- ì§ë¬´ ì´ë¦„ / èŒä½: {role_name}\n")

    skill_values = {
        "korean": seeker.korean_level,
        "chinese": seeker.chinese_level,
        "english": seeker.english_score_level(),
        "major": seeker.major_level(),
        "coding": seeker.coding_level,
    }

    skill_names = {
        "korean": t("skill_korean"),
        "chinese": t("skill_chinese"),
        "english": t("skill_english"),
        "major": t("skill_major"),
        "coding": t("skill_coding"),
    }

    for key, value in skill_values.items():
        w = weights.get(key, 0.0)
        if w <= 0:
            continue

        if value >= 4:
            level = t("level_strong")
        elif value >= 3:
            level = t("level_normal")
        else:
            level = t("level_weak")

        print(f"- {skill_names[key]}: {value}/5  (ê°€ì¤‘ì¹˜: {w:.2f}) â†’ {level}")
    print()


# ==========================
# 3. ì§€ì› í˜„í™© & ê³µê¸°ì—… í† ìµ ì»· ì²´í¬
# ==========================

def handle_apply() -> None:
    while True:
        print("\n" + t("apply_menu_title"))
        print(t("apply_menu_1"))
        print(t("apply_menu_2"))
        print(t("apply_menu_3"))
        print(t("apply_menu_4"))
        print(t("apply_menu_0"))

        choice = input(t("prompt_choice")).strip()

        if choice == "1":
            add_application()
        elif choice == "2":
            list_applications()
        elif choice == "3":
            check_public_toeic()
        elif choice == "4":
            handle_public_institution_crawl()
        elif choice == "0":
            break
        else:
            print(t("invalid_choice"))


def add_application() -> None:
    print()
    company = input(t("ask_company"))
    job_title = input(t("ask_job_title"))
    company_type = input(t("ask_company_type"))
    status = input(t("ask_status"))
    is_public_str = input(t("ask_is_public")).strip().lower()
    is_public = is_public_str == "y"
    toeic_cut_str = input(t("ask_toeic_cut"))
    foreigner_str = input(t("ask_foreigner_friendly")).strip().lower()
    foreigner_friendly = foreigner_str == "y"

    try:
        toeic_cut = int(toeic_cut_str)
    except ValueError:
        toeic_cut = 0

    app = Application(
        company=company,
        job_title=job_title,
        company_type=company_type,
        status=status,
        is_public=is_public,
        toeic_cut=toeic_cut,
        foreigner_friendly=foreigner_friendly,
    )
    applications.append(app)
    print("\n" + t("apply_added") + "\n")
    input(t("press_enter"))


def list_applications() -> None:
    print(t("apply_list_title"))
    if not applications:
        print(t("apply_empty") + "\n")
        input(t("press_enter"))
        return

    for idx, app in enumerate(applications, start=1):
        print(f"{idx}. {app.company} / {app.job_title}")
        print(f"   - íšŒì‚¬ ìœ í˜•: {app.company_type}")
        print(f"   - ìƒíƒœ: {app.status}")
        print(f"   - ê³µê¸°ì—… ì—¬ë¶€: {'ì˜ˆ' if app.is_public else 'ì•„ë‹ˆì˜¤'}")
        print(f"   - ì™¸êµ­ì¸/ìœ í•™ìƒ ê°€ëŠ¥: {'ì˜ˆ' if app.foreigner_friendly else 'ì•„ë‹ˆì˜¤'}")
        if app.is_public and app.toeic_cut > 0:
            print(f"   - í† ìµ ì»·: {app.toeic_cut}")
        print()
    input(t("press_enter"))


def check_public_toeic() -> None:
    if job_seeker.toeic <= 0:
        print("\n" + t("toeic_needed") + "\n")
        input(t("press_enter"))
        return

    print(t("check_public_result_title"))
    any_public = False

    for app in applications:
        if app.is_public and app.toeic_cut > 0:
            any_public = True
            passed = job_seeker.toeic >= app.toeic_cut
            if LANG == "zh":
                result = "æœ‰å¸Œæœ›" if passed else "æœªè¾¾åˆ°åˆ†æ•°çº¿"
            else:
                result = "í†µê³¼ ê°€ëŠ¥" if passed else "ì»· ë¯¸ë‹¬"
            print(
                f"- {app.company} / {app.job_title}: "
                f"ì§€ì›ì TOEIC {job_seeker.toeic} vs ì»· {app.toeic_cut} â†’ {result}"
            )

    if not any_public:
        print("ê³µê¸°ì—…/å…¬ä¼ä¸š ì§€ì› ë‚´ì—­ì´ ì—†ê±°ë‚˜ í† ìµ ì»· ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")

    print()
    input(t("press_enter"))


def handle_public_institution_crawl() -> None:
    """TOEIC ê³µì‹ ì‚¬ì´íŠ¸ + ì •ë¦¬ëœ í‘œ ë°ì´í„°ë¡œ ê³µê³µê¸°ê´€ ì–´í•™ ê¸°ì¤€ í™•ì¸"""
    print("\n[ê³µê³µê¸°ê´€ ì–´í•™ ê¸°ì¤€ í¬ë¡¤ë§]")
    print(
        "â€» í•™ìŠµ/ê³¼ì œìš©ìœ¼ë¡œ, ì„œë²„ ë¶€í•˜ë¥¼ ì¤„ì´ê¸° ìœ„í•´ ì ë‹¹í•œ ì†ë„ë¡œ ìˆ˜ì§‘í•©ë‹ˆë‹¤.\n"
    )

    crawler = PublicInstitutionRecruitCrawler()
    crawler.run()

    if job_seeker.toeic > 0:
        print("\n[ë‚´ TOEIC ì ìˆ˜ì™€ ê°„ë‹¨ ë¹„êµ]")
        my_score = job_seeker.toeic
        for item in crawler.results[:10]:
            req = item['ì–´í•™ìê²©']
            match = re.search(r'TOEIC\s*(\d{3,4})', req)
            if match:
                required = int(match.group(1))
                result = "ì¶©ë¶„" if my_score >= required else "ë¶€ì¡±"
                print(
                    f"- {item['ê¸°ê´€ëª…']} ({item['ì±„ìš©ë¶€ë¬¸']}): "
                    f"ìš”êµ¬ {required}ì  vs ë‚´ ì ìˆ˜ {my_score} â†’ {result}"
                )
    else:
        print("\nâ€» ë‚´ TOEIC ì ìˆ˜ë¥¼ 1ë²ˆ ë©”ë‰´ì—ì„œ ì…ë ¥í•˜ë©´ ë¹„êµ ê²°ê³¼ë„ ë³´ì—¬ì¤ë‹ˆë‹¤.")

    print()
    input(t("press_enter"))


# ==========================
# 4. ìµœì‹  ì±„ìš©ê³µê³  (ì‚¬ëŒì¸ í¬ë¡¤ë§, ì¤‘êµ­ì¸ ìœ í•™ìƒ í•„í„°)
# ==========================

def handle_crawling() -> None:
    """ì¤‘êµ­ì¸ ìœ í•™ìƒì—ê²Œ ìœ ë¦¬í•œ ê³µê³ ë¥¼ ì‹¤ì‹œê°„ í¬ë¡¤ë§í•´ì„œ ë³´ì—¬ì£¼ëŠ” ë©”ë‰´"""
    print("\n" + t("crawl_title"))

    keyword = input(
        "ê²€ìƒ‰ í‚¤ì›Œë“œ (ì˜ˆ: ì¤‘êµ­ì–´, ë¬´ì—­, ë°ì´í„° / ê¸°ë³¸ê°’: ì¤‘êµ­ì–´): "
    ).strip()
    if not keyword:
        keyword = "ì¤‘êµ­ì–´"

    pages_str = input("ê°€ì ¸ì˜¬ í˜ì´ì§€ ìˆ˜ (1~3, ê¸°ë³¸ê°’: 1): ").strip()
    try:
        pages = int(pages_str)
        pages = min(max(pages, 1), 3)
    except ValueError:
        pages = 1

    print(f"\nğŸ” ì‚¬ëŒì¸ì—ì„œ '{keyword}'ë¡œ {pages}í˜ì´ì§€ í¬ë¡¤ë§ ì¤‘...\n")

    crawler = SaraminJobCrawler()
    crawler.crawl(keyword=keyword, pages=pages)

    if not crawler.jobs:
        print(t("crawl_no_match") + "\n")
        input(t("press_enter"))
        return

    keywords = ["ì¤‘êµ­", "ì¤‘êµ­ì–´", "chinese", "ì™¸êµ­ì¸", "ìœ í•™ìƒ", "ç•™å­¦ç”Ÿ"]
    filtered: List[JobPosting] = []
    for jp in crawler.jobs:
        text = " ".join([jp.title, jp.company, jp.location] + jp.tags).lower()
        if any(kw in text for kw in keywords) or jp.foreigner_friendly:
            filtered.append(jp)

    print(t("crawl_list_title"))
    if not filtered:
        print("â€» í¬ë¡¤ë§ì€ ì„±ê³µí–ˆì§€ë§Œ, ì¤‘êµ­/ì™¸êµ­ì¸ ê´€ë ¨ í‚¤ì›Œë“œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        print("  â†’ ì „ì²´ ê³µê³  ì¼ë¶€ë§Œ ë³´ì—¬ë“œë¦½ë‹ˆë‹¤.\n")
        filtered = crawler.jobs

    print(f"ì´ {len(filtered)}ê°œì˜ ê³µê³ ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n")

    for idx, jp in enumerate(filtered[:20], start=1):
        print(f"{idx}. {jp.company} - {jp.title}")
        print(f"   - ê·¼ë¬´ì§€/ì§€ì—­: {jp.location}")
        if jp.tags:
            print(f"   - ì¡°ê±´/íƒœê·¸: {', '.join(jp.tags)}")
        print(
            f"   - ì™¸êµ­ì¸/ìœ í•™ìƒ ìš°ëŒ€: "
            f"{'ì˜ˆ' if jp.foreigner_friendly else 'ì•„ë‹ˆì˜¤'}"
        )
        print()

    input(t("press_enter"))


# ==========================
# 5. ëª…ì–¸ ëœë¤
# ==========================

def handle_quotes() -> None:
    print("\n" + t("quote_title"))

    quotes = [
        ("ì„±ê³µì€ ì¤€ë¹„ëœ ìì—ê²Œ ì˜¨ë‹¤.", "ìµëª…"),
        ("ì²œ ë¦¬ ê¸¸ë„ í•œ ê±¸ìŒë¶€í„°.", "ì†ë‹´/è°šè¯­"),
        ("ì‹¤íŒ¨ëŠ” ì„±ê³µì˜ ì–´ë¨¸ë‹ˆì´ë‹¤.", "ì†ë‹´/è°šè¯­"),
        ("í¬ê¸°í•˜ì§€ ì•ŠëŠ” ê²ƒì´ ê²°êµ­ ê°€ì¥ í° ì¬ëŠ¥ì´ë‹¤.", "ìµëª…"),
        ("ä»Šå¤©å¾ˆæ®‹é…·ï¼Œæ˜å¤©æ›´æ®‹é…·ï¼Œä½†åå¤©å¾ˆç¾å¥½ã€‚", "é©¬äº‘"),
        ("å¤±è´¥æ˜¯æˆåŠŸä¹‹æ¯ã€‚", "è°šè¯­"),
        ("ä¸ç§¯è·¬æ­¥ï¼Œæ— ä»¥è‡³åƒé‡Œã€‚", "è€å­"),
        ("ä½ ç°åœ¨çš„åŠªåŠ›ï¼Œæ˜¯ä¸ºäº†ä»¥åæœ‰æ›´å¤šçš„é€‰æ‹©ã€‚", "ìµëª…/åŒ¿å"),
    ]

    q, author = random.choice(quotes)
    print(f'\n"{q}" - {author}\n')
    input(t("press_enter"))


# ==========================
# 6. ì–¸ì–´ ì„¤ì •
# ==========================

def handle_language_setting() -> None:
    global LANG
    print("\n" + t("lang_menu_title"))
    current_lang_name = t("lang_ko") if LANG == "ko" else t("lang_zh")
    print(t("lang_current") + current_lang_name)

    while True:
        choice = input(t("lang_select")).strip()
        if choice == "1":
            LANG = "ko"
            print(t("lang_changed_ko"))
            break
        elif choice == "2":
            LANG = "zh"
            print(t("lang_changed_zh"))
            break
        elif choice == "0":
            break
        else:
            print(t("invalid_choice"))


# ==========================
# ë©”ì¸ ë£¨í”„
# ==========================

def main() -> None:
    while True:
        print("\n==========================================")
        print(f"   [{t('app_title')}]")
        print("==========================================")
        print(t("menu_1"))
        print(t("menu_2"))
        print(t("menu_3"))
        print(t("menu_4"))
        print(t("menu_5"))
        print(t("menu_6"))
        print(t("menu_0"))
        print("==========================================")

        choice = input(t("prompt_choice")).strip()
        if choice == "1":
            handle_profile()
        elif choice == "2":
            handle_jobs()
        elif choice == "3":
            handle_apply()
        elif choice == "4":
            handle_crawling()
        elif choice == "5":
            handle_quotes()
        elif choice == "6":
            handle_language_setting()
        elif choice == "0":
            print("\n" + t("exit_msg") + "\n")
            break
        else:
            print("\n" + t("invalid_choice"))


if __name__ == "__main__":
    main()
